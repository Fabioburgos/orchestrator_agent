# utils/email_normalizer.py

import re
import unicodedata
import pandas as pd
from typing import List, Dict
from collections import Counter
from custom_logging import get_logger

logger = get_logger(__name__)

class EmailBodyNormalizer:
    """
    Normalizador de cuerpos de correo para estandarizar el texto y mejorar la clasificaci√≥n autom√°tica.
    """
    def __init__(self):
        # ===== PATRONES PARA ELIMINAR FIRMAS Y DISCLAIMERS =====
        self.signature_patterns = [
            # Disclaimers legales comunes (CR√çTICO - AGREGAR PRIMERO)
            r'DISCLAIMER\s*/\s*AVISO\s+LEGAL:.*',
            r'DISCLAIMER:.*',
            r'AVISO\s+LEGAL:.*',
            r'CONFIDENCIALIDAD:.*',
            r'(?:Este mensaje|Esta comunicaci√≥n|This message|This email).*?(?:confidencial|privilegiada|privada).*',
            
            # Avisos de confidencialidad largos (GBM, SIMAN, etc)
            r'La informaci√≥n contenida en este mensaje.*',
            r'Si usted no es el destinatario.*',
            r'Si responde a este mensaje.*',
            
            # Patrones generales de confidencialidad
            r'(?:Este correo|Este email|This email).*?(?:confidencial|privilegiada|confidentiality).*',
            r'^(?:Muchas gracias|Gracias|Saludos|Atentamente|Cordialmente|Regards|Best regards)[\.,]?.*',
            
            # Nombre + Cargo + Empresa (formato t√≠pico de firma)
            r'(?:^|\n)[A-Z√Å√â√ç√ì√ö√ë][a-z√°√©√≠√≥√∫√±]+(?:\s+[A-Z√Å√â√ç√ì√ö√ë][a-z√°√©√≠√≥√∫√±]+)+\s*\n\s*(?:Director|Directora|Gerente|Coordinador|Coordinadora|Jefe|Jefa|Analista|Ingeniero|Ingeniera|Licenciado|Licenciada).*',
            
            # Informaci√≥n de contacto con emojis
            r'[üìßüì±üè¢üåêüíº]\s*[\w\s\:\@\.\-\+\(\)\/]+',
            
            # Informaci√≥n de contacto estructurada
            r'T\.\s*[\d\-\+\(\)]+',
            r'Tel[:\.]?\s*[\d\-\+\(\)]+',
            r'Cel[:\.]?\s*[\d\-\+\(\)]+',
            r'(?:Email|E-mail|Correo)[:\s]+[\w\.\-]+@[\w\.\-]+',
            r'(?:Tel√©fono|Telefono|Phone)[:\s]*[\d\-\+\(\)]+',
            r'(?:Tel√©fono|Telefono|Phone)[:\s]*[\d\-\+\(\)]+',
            r'(?:M√≥vil|Movil|Mobile|Cel)[:\s]*[\d\-\+\(\)]+',
            
            # Separadores visuales (m√°s agresivo)
            r'[‚îÄ‚îÅ‚ïê_\-]{3,}',
            
            # Patr√≥n 21: Emojis de redes sociales y slogans
            r'^[ü§ùüíöüì±üåêüíºüöÄüå±].*',
            
            # Avisos de "no imprimir" / ecol√≥gicos
            r'(?:Antes de imprimir|Before printing).*',
            r'(?:Piense|Think).*?(?:medio ambiente|environment|planeta|planet).*',
            
            # Firmas con redes sociales
            r'(?:S√≠guenos|Siguenos|Follow us|Encu√©ntranos).*',
            r'(?:Facebook|Twitter|LinkedIn|Instagram).*',
            
            # URLs de sitios web
            r'(?:www\.|https?://)\S+',
            
            # Firmas con nombres de empresas comunes
            r'(?:GBM|Siman|Almacenes Siman).*?(?:todos los derechos|all rights|reserved).*',
            
            # Avisos de virus/seguridad
            r'(?:Este mensaje ha sido|This message has been).*?(?:escaneado|scanned).*?(?:virus|malware).*',
            
            # Pol√≠tica de privacidad
            r'(?:Pol√≠tica de privacidad|Privacy policy).*',
            
            # "Enviado desde" (m√≥vil)
            r'Enviado\s+desde\s+(?:mi|my).*?(?:iPhone|iPad|Android|BlackBerry|Samsung).*',
            r'Sent\s+from\s+(?:my|my).*?(?:iPhone|iPad|Android|BlackBerry|Samsung).*',
        ]
        
        # Patrones de ruido com√∫n en emails
        self.noise_patterns = [
            r'Se comparte cuerpo del correo del usuario:.*?Nota:',
            r'Nota: se adjunta correo donde se brinde m√°s informaci√≥n.*',
            r'Se adjunta correo con m√°s detalle',
            r'Se adjunta cuerpo de correo:',
            r'INFORMACI√ìN DEL USUARIO\..*?PASS: \*+',
            r'Nombre completo.*?Pa√≠s.*?Usuarios VPN.*?(\w+\s+\w+.*?\w+\.\w+.*?)*',
            r'Saludos,?\s*Gracias\.?',
            r'Quedamos atentos.*?Saludos cordiales\.',
            r'En espera de sus comentarios\.\s*Gracias',
            r'Quedo a la orden\s*Saludos',
            r'Contact Center - Almacenes Siman',
            r'T\. \d{4}-\d{4}',
            r'Sinceramente,',
            r'Buenos d√≠as,?|Buenas tardes,?|Buen d√≠a,?',
            r'Estimados:?',
            r'@\w+\s+\w+\s+\w+',
            r'Adjunto.*?formulario',
            r'Se adjunt[ao].*?formulario',
        ]
        
        # Patrones para extraer informaci√≥n estructurada
        self.structured_patterns = {
            'usuario': r'[Uu]suario:?\s*(\w+)',
            'nombre': r'[Nn]ombre:?\s*([A-Za-z\s]+)',
            'dui': r'DUI:?\s*(\d{8}-\d)',
            'telefono': r'[Tt]el√©fono:?\s*(\d+)',
            'correo': r'[Cc]orreo:?\s*(\w+@\w+\.\w+)',
            'sistema': r'sistema|aplicaci√≥n|app',
            'desbloqueo': r'desbloque[ao]',
            'renovacion': r'renovaci√≥n|renovar',
            'creacion': r'creaci√≥n|crear|nuevo',
            'baja': r'baja|dar de baja|desactivar',
            'cambio': r'cambio|modificar|actualizar',
            'acceso': r'acceso|acceder|autorizaci√≥n',
            'vpn': r'VPN',
            'licencia': r'licencia',
            'contrase√±a': r'contrase√±a|password|clave',
            'tarjeta': r'tarjeta',
        }
        
        # Stopwords espec√≠ficas del dominio
        self.domain_stopwords = {
            'siman', 'almacenes', 'costa', 'rica', 'salvador', 'guatemala',
            'estimados', 'saludos', 'gracias', 'favor', 'apoyo', 'ayuda',
            'correo', 'formulario', 'adjunto', 'comparto', 'solicito',
            'buen', 'dia', 'buenas', 'tardes', 'buenos', 'dias',
            'nota', 'informacion', 'detalle', 'orden', 'atentos'
        }
        
        # Patrones de ruido com√∫n en emails
        self.noise_patterns = [
            r'Se comparte cuerpo del correo del usuario:.*?Nota:',
            r'Nota: se adjunta correo donde se brinde m√°s informaci√≥n.*',
            r'Se adjunta correo con m√°s detalle',
            r'Se adjunta cuerpo de correo:',
            r'INFORMACI√ìN DEL USUARIO\..*?PASS: \*+',
            r'Nombre completo.*?Pa√≠s.*?Usuarios VPN.*?(\w+\s+\w+.*?\w+\.\w+.*?)*',
            r'Saludos,?\s*Gracias\.?',
            r'Quedamos atentos.*?Saludos cordiales\.',
            r'En espera de sus comentarios\.\s*Gracias',
            r'Quedo a la orden\s*Saludos',
            r'Contact Center - Almacenes Siman',
            r'T\. \d{4}-\d{4}',
            r'Sinceramente,',
            r'Buenos d√≠as,?|Buenas tardes,?|Buen d√≠a,?',
            r'Estimados:?',
            r'@\w+\s+\w+\s+\w+',
            r'Adjunto.*?formulario',
            r'Se adjunt[ao].*?formulario',
        ]
        
        # Patrones para extraer informaci√≥n estructurada
        self.structured_patterns = {
            'usuario': r'[Uu]suario:?\s*(\w+)',
            'nombre': r'[Nn]ombre:?\s*([A-Za-z\s]+)',
            'dui': r'DUI:?\s*(\d{8}-\d)',
            'telefono': r'[Tt]el√©fono:?\s*(\d+)',
            'correo': r'[Cc]orreo:?\s*(\w+@\w+\.\w+)',
            'sistema': r'sistema|aplicaci√≥n|app',
            'desbloqueo': r'desbloque[ao]',
            'renovacion': r'renovaci√≥n|renovar',
            'creacion': r'creaci√≥n|crear|nuevo',
            'baja': r'baja|dar de baja|desactivar',
            'cambio': r'cambio|modificar|actualizar',
            'acceso': r'acceso|acceder|autorizaci√≥n',
            'vpn': r'VPN',
            'licencia': r'licencia',
            'contrase√±a': r'contrase√±a|password|clave',
            'tarjeta': r'tarjeta',
        }
        
        # Stopwords espec√≠ficas del dominio
        self.domain_stopwords = {
            'siman', 'almacenes', 'costa', 'rica', 'salvador', 'guatemala',
            'estimados', 'saludos', 'gracias', 'favor', 'apoyo', 'ayuda',
            'correo', 'formulario', 'adjunto', 'comparto', 'solicito',
            'buen', 'dia', 'buenas', 'tardes', 'buenos', 'dias',
            'nota', 'informacion', 'detalle', 'orden', 'atentos'
        }

    def remove_signatures_and_disclaimers(self, text: str) -> str:
        """
        Elimina firmas empresariales y disclaimers del texto.
        """
        cleaned_text = text

        logger.debug("=== LIMPIEZA DE FIRMAS Y DISCLAIMERS ===")
        logger.debug(f"Texto original length: {len(text)}")

        # 1. Detectar punto de corte de despedida
        despedida_patterns = [
            r'Muchas gracias por su apoyo',
            r'Gracias por su ayuda',
            r'Saludos cordiales',
            r'Atentamente',
            r'Cordialmente',
            r'Quedo atento',
            r'Quedamos atentos',
        ]

        earliest_cutoff = len(cleaned_text)
        for pattern in despedida_patterns:
            match = re.search(pattern, cleaned_text, re.IGNORECASE)
            if match and match.start() < earliest_cutoff:
                earliest_cutoff = match.start()
                logger.debug(f"Punto de corte encontrado en: {pattern} (posici√≥n {match.start()})")

        # Si encontramos despedida, cortar desde ah√≠
        if earliest_cutoff < len(cleaned_text):
            cleaned_text = cleaned_text[:earliest_cutoff].strip()
            logger.debug(f"Texto cortado desde despedida: {len(cleaned_text)} caracteres")

        # 2. Aplicar patrones de firma uno por uno
        for i, pattern in enumerate(self.signature_patterns):
            try:
                before_length = len(cleaned_text)
                matches = list(re.finditer(pattern, cleaned_text, flags=re.IGNORECASE | re.DOTALL | re.MULTILINE))

                if matches:
                    for match in matches:
                        removed_text = match.group(0)
                        if len(removed_text) > 20:  # Solo loggear si es significativo
                            preview = removed_text[:80].replace('\n', ' ')
                            logger.debug(f"Patr√≥n {i+1} elimin√≥: '{preview}...'")

                cleaned_text = re.sub(pattern, '', cleaned_text, flags=re.IGNORECASE | re.DOTALL | re.MULTILINE)

                after_length = len(cleaned_text)
                if before_length != after_length:
                    logger.debug(f"  Reducci√≥n: {before_length} -> {after_length} caracteres")

            except Exception as e:
                logger.error(f"Error en patr√≥n {i+1}: {e}")
                continue

        # 3. Limpiar espacios m√∫ltiples resultantes
        cleaned_text = re.sub(r'\s+', ' ', cleaned_text)
        cleaned_text = cleaned_text.strip()

        logger.debug(f"Texto despu√©s de limpiar firmas length: {len(cleaned_text)}")

        return cleaned_text

    def remove_noise(self, text: str) -> str:
        """Elimina patrones de ruido comunes en los emails."""
        cleaned_text = text
        
        for pattern in self.noise_patterns:
            cleaned_text = re.sub(pattern, '', cleaned_text, flags=re.IGNORECASE | re.DOTALL)
        
        return cleaned_text.strip()

    def normalize_unicode(self, text: str) -> str:
        """Normaliza caracteres Unicode y acentos."""
        text = unicodedata.normalize('NFKD', text)
        text = ''.join(c for c in text if not unicodedata.combining(c))
        return text

    def standardize_whitespace(self, text: str) -> str:
        """Estandariza espacios en blanco y saltos de l√≠nea."""
        text = re.sub(r'\s+', ' ', text)
        text = text.strip()
        return text

    def extract_key_actions(self, text: str) -> List[str]:
        """Extrae las acciones clave del texto."""
        actions = []
        text_lower = text.lower()
        
        action_keywords = {
            'crear': ['crear', 'creacion', 'nuevo', 'nueva', 'alta'],
            'modificar': ['modificar', 'cambiar', 'cambio', 'actualizar'],
            'desbloquear': ['desbloquear', 'desbloqueo', 'restablecer'],
            'renovar': ['renovar', 'renovacion'],
            'eliminar': ['eliminar', 'baja', 'dar de baja', 'desactivar'],
            'acceder': ['acceso', 'acceder', 'autorizacion', 'habilitar'],
            'solicitar': ['solicitar', 'solicitud', 'requiere', 'necesita']
        }
        
        for action, keywords in action_keywords.items():
            if any(keyword in text_lower for keyword in keywords):
                actions.append(action)
        
        return actions

    def extract_entities(self, text: str) -> Dict[str, List[str]]:
        """Extrae entidades estructuradas del texto."""
        entities = {}
        
        for entity_type, pattern in self.structured_patterns.items():
            if entity_type in ['sistema', 'desbloqueo', 'renovacion', 'creacion', 'baja', 'cambio', 'acceso', 'vpn', 'licencia', 'contrase√±a', 'tarjeta']:
                # Para conceptos, solo verificar presencia
                if re.search(pattern, text, re.IGNORECASE):
                    entities[entity_type] = ['presente']
            else:
                # Para datos espec√≠ficos, extraer valores
                matches = re.findall(pattern, text, re.IGNORECASE)
                if matches:
                    entities[entity_type] = matches
        
        return entities

    def create_normalized_features(self, text: str) -> Dict[str, any]:
        """Crea caracter√≠sticas normalizadas del texto."""
        entities = self.extract_entities(text)
        actions = self.extract_key_actions(text)
        
        features = {
            'tiene_usuario': 'usuario' in entities,
            'tiene_nombre': 'nombre' in entities,
            'tiene_dui': 'dui' in entities,
            'tiene_sistema': 'sistema' in entities,
            'accion_crear': 'crear' in actions,
            'accion_modificar': 'modificar' in actions,
            'accion_desbloquear': 'desbloquear' in actions,
            'accion_renovar': 'renovar' in actions,
            'accion_eliminar': 'eliminar' in actions,
            'accion_acceder': 'acceder' in actions,
            'accion_solicitar': 'solicitar' in actions,
            'involucra_vpn': 'vpn' in entities,
            'involucra_licencia': 'licencia' in entities,
            'involucra_contrase√±a': 'contrase√±a' in entities,
            'involucra_tarjeta': 'tarjeta' in entities,
            'num_acciones': len(actions),
            'num_entidades': len(entities)
        }
        
        return features

    def normalize_email_body(self, text: str) -> Dict[str, any]:
        """
        Normaliza completamente el cuerpo del correo.
        """
        logger.info("="*80)
        logger.info("INICIANDO NORMALIZACI√ìN COMPLETA")
        logger.info("="*80)

        # 1. Eliminar firmas y disclaimers (NUEVO - PRIMERO)
        logger.info(">>> PASO 1: Eliminando firmas y disclaimers...")
        text_sin_firmas = self.remove_signatures_and_disclaimers(text)
        logger.info(f"Resultado: {len(text)} -> {len(text_sin_firmas)} caracteres")

        # 2. Limpieza b√°sica de ruido
        logger.info(">>> PASO 2: Limpiando ruido...")
        normalized_text = self.remove_noise(text_sin_firmas)

        # 3. Normalizar unicode
        logger.info(">>> PASO 3: Normalizando unicode...")
        normalized_text = self.normalize_unicode(normalized_text)

        # 4. Estandarizar espacios
        logger.info(">>> PASO 4: Estandarizando espacios...")
        normalized_text = self.standardize_whitespace(normalized_text)

        # 5. Extracci√≥n de caracter√≠sticas (del texto original)
        logger.info(">>> PASO 5: Extrayendo caracter√≠sticas...")
        features = self.create_normalized_features(text)

        # 6. Crear resumen estructurado
        entities = self.extract_entities(text)
        actions = self.extract_key_actions(text)

        # 7. Generar texto normalizado final (contenido esencial)
        logger.info(">>> PASO 7: Extrayendo contenido esencial...")
        essential_text = self.extract_essential_content(normalized_text)

        logger.info("="*80)
        logger.info("NORMALIZACI√ìN COMPLETADA")
        logger.info("="*80)
        logger.info(f"Texto original: {len(text)} caracteres")
        logger.info(f"Texto sin firmas: {len(text_sin_firmas)} caracteres")
        logger.info(f"Texto final: {len(essential_text)} caracteres")
        reduction_pct = ((len(text) - len(essential_text)) / len(text) * 100) if len(text) > 0 else 0
        logger.info(f"Reducci√≥n total: {len(text) - len(essential_text)} caracteres ({reduction_pct:.1f}%)")
        logger.debug(f"\nTexto final limpio:\n{essential_text}\n")

        return {
            'texto_normalizado': essential_text,
            'texto_limpio': normalized_text,
            'texto_sin_firmas': text_sin_firmas,
            'acciones': actions,
            'entidades': entities,
            'caracteristicas': features,
            'texto_original': text,
            'estadisticas': {
                'longitud_original': len(text),
                'longitud_sin_firmas': len(text_sin_firmas),
                'longitud_final': len(essential_text),
                'reduccion_porcentaje': reduction_pct
            }
        }

    def extract_essential_content(self, text: str) -> str:
        """Extrae solo el contenido esencial del correo."""
        # Remover frases de cortes√≠a comunes
        courtesy_patterns = [
            r'buen d√≠a|buenos d√≠as|buenas tardes',
            r'estimados?:?',
            r'saludos,?\s*gracias',
            r'quedo a la orden',
            r'quedamos atentos',
            r'en espera de sus comentarios',
            r'un placer saludarle',
            r'agradecer√© su ayuda',
            r'de su valiosa ayuda'
        ]
        
        essential_text = text
        for pattern in courtesy_patterns:
            essential_text = re.sub(pattern, '', essential_text, flags=re.IGNORECASE)
        
        # Limpiar espacios resultantes
        essential_text = self.standardize_whitespace(essential_text)
        
        return essential_text

    def batch_normalize(self, df: pd.DataFrame, text_column: str = 'descripcion') -> pd.DataFrame:
        """Normaliza un DataFrame completo de correos."""
        results = []
        
        for idx, row in df.iterrows():
            text = row[text_column]
            normalized = self.normalize_email_body(text)
            
            # Crear fila con datos normalizados
            new_row = row.copy()
            new_row['texto_normalizado'] = normalized['texto_normalizado']
            new_row['texto_limpio'] = normalized['texto_limpio']
            new_row['acciones_detectadas'] = '|'.join(normalized['acciones'])
            new_row['entidades_detectadas'] = '|'.join(normalized['entidades'].keys())
            
            # Agregar caracter√≠sticas como columnas
            for feature, value in normalized['caracteristicas'].items():
                new_row[f'feature_{feature}'] = value
                
            results.append(new_row)
        
        return pd.DataFrame(results)

# Funci√≥n para an√°lisis de normalizaci√≥n
def analyze_normalization_impact(original_df: pd.DataFrame, normalized_df: pd.DataFrame):
    """Analiza el impacto de la normalizaci√≥n en los datos."""
    logger.info("=== AN√ÅLISIS DE NORMALIZACI√ìN ===\n")

    # Estad√≠sticas b√°sicas
    logger.info("1. ESTAD√çSTICAS B√ÅSICAS:")
    logger.info(f"Emails procesados: {len(original_df)}")

    # Longitud promedio antes y despu√©s
    orig_lengths = original_df['descripcion'].str.len()
    norm_lengths = normalized_df['texto_normalizado'].str.len()

    logger.info(f"Longitud promedio original: {orig_lengths.mean():.1f} caracteres")
    logger.info(f"Longitud promedio normalizada: {norm_lengths.mean():.1f} caracteres")
    reduction_avg = ((orig_lengths.mean() - norm_lengths.mean()) / orig_lengths.mean() * 100)
    logger.info(f"Reducci√≥n promedio: {reduction_avg:.1f}%")

    # An√°lisis de acciones detectadas
    logger.info("\n2. ACCIONES M√ÅS COMUNES:")
    all_actions = []
    for actions_str in normalized_df['acciones_detectadas']:
        if pd.notna(actions_str) and actions_str:
            all_actions.extend(actions_str.split('|'))

    action_counts = Counter(all_actions)
    for action, count in action_counts.most_common(10):
        logger.info(f"   {action}: {count} veces")

    # An√°lisis de entidades
    logger.info("\n3. ENTIDADES M√ÅS COMUNES:")
    all_entities = []
    for entities_str in normalized_df['entidades_detectadas']:
        if pd.notna(entities_str) and entities_str:
            all_entities.extend(entities_str.split('|'))

    entity_counts = Counter(all_entities)
    for entity, count in entity_counts.most_common(10):
        logger.info(f"   {entity}: {count} veces")